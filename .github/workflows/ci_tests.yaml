# Test PyGMT on Linux/macOS/Windows
#
# This workflow runs regular PyGMT tests and uploads test coverage reports stored in
# `.coverage.xml` to https://app.codecov.io/gh/GenericMappingTools/pygmt via the
# [Codecov GitHub Action](https://github.com/codecov/codecov-action). More codecov
# related configurations are stored in `.github/codecov.yml`. If any tests fail, it also
# uploads the diff images as workflow artifacts.
#
# It is run:
# 1. on every commit to the main branch
# 2. on every commit to the pull request branches, unless the pull requests only contain
#    non-code changes.
# 3. when a new release is published
#
# It is also scheduled to run daily on the main branch.
#
# In draft pull request, only jobs on Linux are triggered to save on Continuous
# Integration resources:
#
# - Minimum supported Python + core packages (minimum supported versions)
#   + optional packages (minimum supported versions if any)
# - Latest Python + core packages (latest versions) + optional packages
# - Last release before the latest Python + core packages
#
name: Tests

on:
  push:
    branches: [ main ]
    paths:
      - 'pygmt/**'
      - '.github/workflows/ci_tests.yaml'
  pull_request:
    types: [opened, reopened, synchronize, ready_for_review]
    paths:
      - 'pygmt/**'
      - '.github/workflows/ci_tests.yaml'
  workflow_dispatch:
  release:
    types:
      - published
  # Schedule daily tests
  schedule:
    - cron: '0 0 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

jobs:
  test:
    name: ${{ matrix.os }} - Python ${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    permissions:
      id-token: write  # This is required for requesting OIDC token for codecov
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.12', '3.14']
        os: [ubuntu-latest, ubuntu-24.04-arm, macos-latest, windows-latest]
        # Is it a draft Pull Request (true or false)?
        isDraft:
          - ${{ github.event.pull_request.draft }}
        # Only run jobs on Ubuntu for draft PRs
        exclude:
          - os: ubuntu-24.04-arm
            isDraft: true
          - os: macos-latest
            isDraft: true
          - os: windows-latest
            isDraft: true
        include:
          # Python 3.12 + core packages (minimum supported versions) + optional packages (minimum supported versions if any)
          - python-version: '3.12'
            numpy-version: '2.0'
            pandas-version: '=2.2'
            xarray-version: '=2024.5'
            optional-packages: ' contextily geopandas ipython pyarrow-core rioxarray netCDF4 sphinx-gallery'
          # Python 3.14 + core packages (latest versions) + optional packages
          - python-version: '3.14'
            numpy-version: '2.4'
            pandas-version: ''
            xarray-version: ''
            optional-packages: ' contextily geopandas ipython pyarrow-core rioxarray netCDF4 sphinx-gallery'
          # Python 3.13 + core packages (Linux only)
          - os: 'ubuntu-latest'
            python-version: '3.13'
            numpy-version: ''
            pandas-version: ''
            xarray-version: ''
            optional-packages: ''

    timeout-minutes: 30
    defaults:
      run:
        shell: bash -l {0}

    # Environment variables used by codecov
    env:
      OS: ${{ matrix.os }}
      PYTHON: ${{ matrix.python-version }}
      NUMPY: ${{ matrix.numpy-version }}

    steps:
      # Checkout current git repository
      - name: Checkout
        uses: actions/checkout@v6.0.1
        with:
          # fetch all history so that setuptools-scm works
          fetch-depth: 0
          persist-credentials: false

      - name: Get current week number of year
        id: date
        run: echo "date=$(date +%Y-W%W)" >> $GITHUB_OUTPUT  # e.g., 2024-W19

      # Install Micromamba with conda-forge dependencies
      - name: Setup Micromamba
        uses: mamba-org/setup-micromamba@add3a49764cedee8ee24e82dfde87f5bc2914462 # v2.0.7
        with:
          environment-name: pygmt
          cache-environment: true
          # environment cache is persistent for one week.
          cache-environment-key: micromamba-environment-${{ steps.date.outputs.date }}
          create-args: >-
            python=${{ matrix.python-version }}${{ matrix.optional-packages }}
            gmt=6.6.0
            ghostscript=10.06.0
            numpy=${{ matrix.numpy-version }}
            pandas${{ matrix.pandas-version }}
            xarray${{ matrix.xarray-version }}
            packaging
            make
            pip
            python-build
            pytest
            pytest-cov
            pytest-doctestplus
            pytest-mpl
            pytest-rerunfailures

      # Download cached remote files (artifacts) from GitHub
      - name: Download remote data from GitHub
        run: |
          # Download files to ~/.gmt directory and list them
          gh run download --name gmt-cache --dir ~/.gmt/
          # Change modification times of the two files, so GMT won't refresh it
          touch ~/.gmt/gmt_data_server.txt ~/.gmt/gmt_hash_server.txt
          ls -lhR ~/.gmt
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Install uv
        uses: astral-sh/setup-uv@eac588ad8def6316056a12d4907a9d4d84ff7a3b # v7.3.0
        with:
          activate-environment: true
          python-version: ${{ matrix.python-version }}

      - name: Install dvc
        run: |
          uv pip install dvc
          uv pip list

      # Pull baseline image data from dvc remote (DAGsHub)
      - name: Pull baseline image data from dvc remote
        id: dvc-pull
        continue-on-error: true
        run: |
          uv run dvc remote modify upstream url https://${DAGSHUB_TOKEN}@dagshub.com/GenericMappingTools/pygmt.dvc --local
          uv run dvc pull --no-run-cache --verbose && ls -lhR pygmt/tests/baseline/
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}

      - name: Download DVC cache as artifacts from GitHub
        if: steps.dvc-pull.outcome == 'failure'
        run: |
          rm -rvf .dvc/cache/
          gh run download --name dvc-cache --dir .dvc/cache/
          uv run dvc checkout --verbose
        env:
          GH_TOKEN: ${{ github.token }}

      # Install the package that we want to test
      - name: Install the package
        run: make install

      # Run the regular tests
      - name: Run tests
        run: make test PYTEST_EXTRA="-r P --reruns 2"

      # Upload diff images on test failure
      - name: Upload diff images if any test fails
        uses: actions/upload-artifact@v6.0.0
        if: failure()
        with:
          name: artifact-${{ matrix.os }}-${{ matrix.python-version }}
          path: tmp-test-dir-with-unique-name

      # Upload coverage to Codecov
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@671740ac38dd9b0130fbe1cec585b89eea48d3de # v5.5.2
        if: success() || failure()
        with:
          use_oidc: true
          files: ./coverage.xml # optional
          env_vars: OS,PYTHON,NUMPY
          fail_ci_if_error: false
